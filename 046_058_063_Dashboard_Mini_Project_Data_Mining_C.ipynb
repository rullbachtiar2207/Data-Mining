{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Langkah 1: Install Dependensi\n",
        "\n",
        "Install Streamlit dan Library Pendukung:\n",
        "- streamlit\n",
        "- pandas\n",
        "- plotly\n",
        "- networkx\n",
        "- scikit-learn\n",
        "- numpy"
      ],
      "metadata": {
        "id": "cNGOtXvxIYJW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcYBLtaW15JC",
        "outputId": "8999a326-88ab-41eb-c211-4b31d39e8e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas plotly networkx scikit-learn numpy"
      ],
      "metadata": {
        "id": "44z44RUoLKYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa949eae-e2cb-46ce-a7b0-4a11be170546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Localtunnel (untuk membuka dashboard secara publik):"
      ],
      "metadata": {
        "id": "DK6kR4-RJXN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwAOylID2BBj",
        "outputId": "9847ea74-06f2-4d2b-ad64-02a003ef767f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langkah 2: Menjalankan Aplikasi Streamlit"
      ],
      "metadata": {
        "id": "NANQFHnaIeqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import networkx as nx\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Konfigurasi halaman\n",
        "st.set_page_config(\n",
        "    page_title=\"Job Matching System - GNN & GAT\",\n",
        "    page_icon=\"üîó\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# CSS untuk styling\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    /* Import Google Fonts */\n",
        "    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');\n",
        "\n",
        "    /* Global Styling - Clean White Theme */\n",
        "    .main {\n",
        "        padding-top: 1rem;\n",
        "        font-family: 'Inter', sans-serif;\n",
        "        background-color: #ffffff;\n",
        "    }\n",
        "\n",
        "    /* Clean White Background */\n",
        "    .stApp {\n",
        "        background-color: #f8f9fa;\n",
        "    }\n",
        "\n",
        "    /* Clean Sidebar */\n",
        "    .css-1d391kg {\n",
        "        background: #ffffff;\n",
        "        border-right: 2px solid #e9ecef;\n",
        "        box-shadow: 2px 0 10px rgba(0,0,0,0.05);\n",
        "    }\n",
        "\n",
        "    /* Main Container - Clean */\n",
        "    .block-container {\n",
        "        background: #ffffff;\n",
        "        border-radius: 12px;\n",
        "        border: 1px solid #e9ecef;\n",
        "        box-shadow: 0 2px 12px rgba(0, 0, 0, 0.08);\n",
        "        padding: 2rem;\n",
        "        margin: 1rem;\n",
        "    }\n",
        "\n",
        "    /* Enhanced Metrics - Clean with Subtle Gradients */\n",
        "    .metric-container {\n",
        "        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 12px;\n",
        "        border: 2px solid #e9ecef;\n",
        "        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05);\n",
        "        text-align: center;\n",
        "        transition: all 0.3s ease;\n",
        "        margin: 0.5rem 0;\n",
        "    }\n",
        "\n",
        "    .metric-container:hover {\n",
        "        transform: translateY(-3px);\n",
        "        box-shadow: 0 6px 20px rgba(0, 0, 0, 0.1);\n",
        "        border-color: #3498db;\n",
        "    }\n",
        "\n",
        "    .metric-value {\n",
        "        font-size: 2.5rem;\n",
        "        font-weight: 700;\n",
        "        background: linear-gradient(45deg, #3498db, #2980b9);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "        background-clip: text;\n",
        "    }\n",
        "\n",
        "    .metric-label {\n",
        "        font-size: 0.9rem;\n",
        "        color: #6c757d;\n",
        "        font-weight: 500;\n",
        "        margin-top: 0.5rem;\n",
        "    }\n",
        "\n",
        "    /* Clean Cards with Subtle Accent */\n",
        "    .job-card {\n",
        "        background: #ffffff;\n",
        "        border: 1px solid #e9ecef;\n",
        "        border-radius: 12px;\n",
        "        padding: 1.5rem;\n",
        "        margin: 1rem 0;\n",
        "        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n",
        "        transition: all 0.3s ease;\n",
        "        position: relative;\n",
        "        overflow: hidden;\n",
        "    }\n",
        "\n",
        "    .job-card::before {\n",
        "        content: '';\n",
        "        position: absolute;\n",
        "        top: 0;\n",
        "        left: 0;\n",
        "        right: 0;\n",
        "        height: 3px;\n",
        "        background: linear-gradient(90deg, #3498db, #2ecc71);\n",
        "        background-size: 200% 200%;\n",
        "        animation: gradientShift 3s ease infinite;\n",
        "    }\n",
        "\n",
        "    .job-card:hover {\n",
        "        transform: translateY(-5px);\n",
        "        box-shadow: 0 8px 25px rgba(0, 0, 0, 0.1);\n",
        "        border-color: #3498db;\n",
        "    }\n",
        "\n",
        "    .profile-card {\n",
        "        background: #ffffff;\n",
        "        border: 1px solid #e9ecef;\n",
        "        border-radius: 12px;\n",
        "        padding: 1.5rem;\n",
        "        margin: 1rem 0;\n",
        "        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n",
        "        transition: all 0.3s ease;\n",
        "    }\n",
        "\n",
        "    .profile-card:hover {\n",
        "        transform: translateY(-3px);\n",
        "        box-shadow: 0 6px 20px rgba(0, 0, 0, 0.08);\n",
        "        border-color: #3498db;\n",
        "    }\n",
        "\n",
        "    /* Animation Keyframes */\n",
        "    @keyframes gradientShift {\n",
        "        0% { background-position: 0% 50%; }\n",
        "        50% { background-position: 100% 50%; }\n",
        "        100% { background-position: 0% 50%; }\n",
        "    }\n",
        "\n",
        "    @keyframes pulse {\n",
        "        0% { box-shadow: 0 0 0 0 rgba(52, 152, 219, 0.4); }\n",
        "        70% { box-shadow: 0 0 0 8px rgba(52, 152, 219, 0); }\n",
        "        100% { box-shadow: 0 0 0 0 rgba(52, 152, 219, 0); }\n",
        "    }\n",
        "\n",
        "    /* Clean Buttons with Gradient */\n",
        "    .stButton > button {\n",
        "        background: linear-gradient(45deg, #3498db, #2980b9);\n",
        "        color: white;\n",
        "        border: none;\n",
        "        border-radius: 8px;\n",
        "        padding: 0.75rem 2rem;\n",
        "        font-weight: 600;\n",
        "        font-size: 1rem;\n",
        "        box-shadow: 0 2px 8px rgba(52, 152, 219, 0.3);\n",
        "        transition: all 0.3s ease;\n",
        "        text-transform: uppercase;\n",
        "        letter-spacing: 0.5px;\n",
        "    }\n",
        "\n",
        "    .stButton > button:hover {\n",
        "        transform: translateY(-2px);\n",
        "        box-shadow: 0 4px 15px rgba(52, 152, 219, 0.4);\n",
        "        background: linear-gradient(45deg, #2980b9, #3498db);\n",
        "    }\n",
        "\n",
        "    /* Clean Selectbox */\n",
        "    .stSelectbox > div > div {\n",
        "        background: #f8f9fa;\n",
        "        border: 1px solid #e9ecef;\n",
        "        border-radius: 8px;\n",
        "    }\n",
        "\n",
        "    /* Page Headers - Clean */\n",
        "    .page-header {\n",
        "        text-align: center;\n",
        "        padding: 2rem 0;\n",
        "        margin-bottom: 2rem;\n",
        "        background: linear-gradient(135deg, #f8f9fa 0%, #ffffff 100%);\n",
        "        border-radius: 12px;\n",
        "        border: 1px solid #e9ecef;\n",
        "    }\n",
        "\n",
        "    .page-title {\n",
        "        font-size: 2.8rem;\n",
        "        font-weight: 700;\n",
        "        background: linear-gradient(45deg, #2c3e50, #3498db);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "        background-clip: text;\n",
        "        margin-bottom: 0.5rem;\n",
        "    }\n",
        "\n",
        "    .page-subtitle {\n",
        "        font-size: 1.1rem;\n",
        "        color: #6c757d;\n",
        "        font-weight: 400;\n",
        "    }\n",
        "\n",
        "    /* Status Indicators - Clean */\n",
        "    .status-indicator {\n",
        "        display: inline-block;\n",
        "        width: 10px;\n",
        "        height: 10px;\n",
        "        border-radius: 50%;\n",
        "        margin-right: 8px;\n",
        "        animation: pulse 2s infinite;\n",
        "    }\n",
        "\n",
        "    .status-active { background-color: #28a745; }\n",
        "    .status-pending { background-color: #ffc107; }\n",
        "    .status-inactive { background-color: #dc3545; }\n",
        "\n",
        "    /* Clean Progress Bars */\n",
        "    .progress-container {\n",
        "        background: #f8f9fa;\n",
        "        border-radius: 8px;\n",
        "        padding: 3px;\n",
        "        margin: 0.5rem 0;\n",
        "        border: 1px solid #e9ecef;\n",
        "    }\n",
        "\n",
        "    .progress-bar {\n",
        "        height: 6px;\n",
        "        border-radius: 5px;\n",
        "        background: linear-gradient(90deg, #3498db, #2ecc71);\n",
        "        transition: width 0.5s ease;\n",
        "    }\n",
        "\n",
        "    /* Clean Expander */\n",
        "    .streamlit-expanderHeader {\n",
        "        background: #f8f9fa;\n",
        "        border-radius: 8px;\n",
        "        border: 1px solid #e9ecef;\n",
        "    }\n",
        "\n",
        "    /* Clean Footer */\n",
        "    .footer {\n",
        "        background: #ffffff;\n",
        "        border-radius: 12px;\n",
        "        padding: 1.5rem;\n",
        "        text-align: center;\n",
        "        margin-top: 2rem;\n",
        "        border: 1px solid #e9ecef;\n",
        "        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n",
        "    }\n",
        "\n",
        "    /* Text Colors for Clean Theme */\n",
        "    h1, h2, h3, h4, h5, h6 {\n",
        "        color: #7998b8 !important;\n",
        "    }\n",
        "\n",
        "    .stMarkdown {\n",
        "        color: #495057;\n",
        "    }\n",
        "\n",
        "    /* Responsive Design */\n",
        "    @media (max-width: 768px) {\n",
        "        .page-title { font-size: 2rem; }\n",
        "        .metric-value { font-size: 2rem; }\n",
        "        .block-container { margin: 0.5rem; padding: 1rem; }\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# === FUNGSI HELPER UNTUK METRICS ===\n",
        "def create_metric_card(label, value, icon=\"üìä\"):\n",
        "    \"\"\"Membuat metric card yang lebih menarik\"\"\"\n",
        "    return f\"\"\"\n",
        "    <div class=\"metric-container\">\n",
        "        <div style=\"font-size: 2rem; margin-bottom: 0.5rem;\">{icon}</div>\n",
        "        <div class=\"metric-value\">{value}</div>\n",
        "        <div class=\"metric-label\">{label}</div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "def create_progress_bar(percentage, label=\"Progress\"):\n",
        "    \"\"\"Membuat progress bar yang menarik\"\"\"\n",
        "    return f\"\"\"\n",
        "    <div style=\"margin: 1rem 0;\">\n",
        "        <div style=\"display: flex; justify-content: between; margin-bottom: 0.5rem;\">\n",
        "            <span style=\"color: #ecf0f1; font-weight: 500;\">{label}</span>\n",
        "            <span style=\"color: #3498db; font-weight: 600;\">{percentage}%</span>\n",
        "        </div>\n",
        "        <div class=\"progress-container\">\n",
        "            <div class=\"progress-bar\" style=\"width: {percentage}%;\"></div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "def create_status_badge(status, text):\n",
        "    \"\"\"Membuat status badge dengan styling clean\"\"\"\n",
        "    status_class = f\"status-{status}\"\n",
        "    return f\"\"\"\n",
        "    <span style=\"display: inline-flex; align-items: center; background: #f8f9fa;\n",
        "          padding: 0.5rem 1rem; border-radius: 20px; margin: 0.25rem;\n",
        "          border: 1px solid #e9ecef;\">\n",
        "        <span class=\"status-indicator {status_class}\"></span>\n",
        "        <span style=\"color: #495057; font-weight: 500;\">{text}</span>\n",
        "    </span>\n",
        "    \"\"\"\n",
        "\n",
        "# Fungsi untuk memuat dan memproses data\n",
        "@st.cache_data\n",
        "def load_datasets():\n",
        "    \"\"\"Memuat dataset dari file CSV\"\"\"\n",
        "    try:\n",
        "        # Load datasets\n",
        "        profiles_df = pd.read_csv('https://github.com/wempy-aditya/projek_mk_data_mining/raw/refs/heads/main/dashboard/user_profiles.csv')\n",
        "        jobs_df = pd.read_csv('https://github.com/wempy-aditya/projek_mk_data_mining/raw/refs/heads/main/dashboard/job_postings.csv')\n",
        "\n",
        "        # Basic data cleaning\n",
        "        profiles_df = profiles_df.dropna(subset=['name', 'position'])\n",
        "        jobs_df = jobs_df.dropna(subset=['title', 'description'])\n",
        "\n",
        "        return profiles_df, jobs_df\n",
        "    except FileNotFoundError:\n",
        "        st.error(\"Dataset files not found. Please ensure the CSV files are in the correct location.\")\n",
        "        return None, None\n",
        "\n",
        "@st.cache_data\n",
        "def extract_skills_from_text(text):\n",
        "    \"\"\"Ekstrak skill dari teks menggunakan pattern matching\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return []\n",
        "\n",
        "    # Daftar skills umum untuk matching\n",
        "    common_skills = [\n",
        "        'python', 'java', 'javascript', 'sql', 'machine learning', 'data science',\n",
        "        'analytics', 'tensorflow', 'pytorch', 'react', 'node.js', 'docker',\n",
        "        'kubernetes', 'aws', 'azure', 'gcp', 'mongodb', 'postgresql', 'mysql',\n",
        "        'git', 'agile', 'scrum', 'project management', 'leadership', 'communication',\n",
        "        'excel', 'powerbi', 'tableau', 'spark', 'hadoop', 'deep learning',\n",
        "        'nlp', 'computer vision', 'devops', 'ci/cd', 'microservices'\n",
        "    ]\n",
        "\n",
        "    text_lower = text.lower()\n",
        "    found_skills = []\n",
        "\n",
        "    for skill in common_skills:\n",
        "        if skill.lower() in text_lower:\n",
        "            found_skills.append(skill.title())\n",
        "\n",
        "    return found_skills\n",
        "\n",
        "@st.cache_data\n",
        "def process_data_for_matching(profiles_df, jobs_df):\n",
        "    \"\"\"Memproses data untuk job matching\"\"\"\n",
        "    # Extract skills dari profil\n",
        "    profiles_df['extracted_skills'] = profiles_df.apply(\n",
        "        lambda row: extract_skills_from_text(\n",
        "            str(row.get('about', '')) + ' ' +\n",
        "            str(row.get('position', '')) + ' ' +\n",
        "            str(row.get('experience', ''))\n",
        "        ), axis=1\n",
        "    )\n",
        "\n",
        "    # Extract skills dari job descriptions\n",
        "    jobs_df['extracted_skills'] = jobs_df['description'].apply(extract_skills_from_text)\n",
        "\n",
        "    # Create skill vectors for similarity calculation\n",
        "    all_skills = set()\n",
        "    for skills in profiles_df['extracted_skills']:\n",
        "        all_skills.update(skills)\n",
        "    for skills in jobs_df['extracted_skills']:\n",
        "        all_skills.update(skills)\n",
        "\n",
        "    all_skills = list(all_skills)\n",
        "\n",
        "    return profiles_df, jobs_df, all_skills\n",
        "\n",
        "def calculate_job_similarity_matrix(jobs_df, all_skills):\n",
        "    \"\"\"Menghitung similarity matrix untuk jobs berdasarkan skills\"\"\"\n",
        "    # Create binary skill matrix\n",
        "    skill_matrix = []\n",
        "    for _, job in jobs_df.iterrows():\n",
        "        skill_vector = [1 if skill in job['extracted_skills'] else 0 for skill in all_skills]\n",
        "        skill_matrix.append(skill_vector)\n",
        "\n",
        "    skill_matrix = np.array(skill_matrix)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    if skill_matrix.shape[1] > 0:\n",
        "        similarity_matrix = cosine_similarity(skill_matrix)\n",
        "    else:\n",
        "        similarity_matrix = np.zeros((len(jobs_df), len(jobs_df)))\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "def simulate_gnn_predictions(profiles_df, jobs_df, all_skills, model_type=\"GNN\"):\n",
        "    \"\"\"Simulasi prediksi GNN/GAT untuk job matching\"\"\"\n",
        "    # Create compatibility scores\n",
        "    compatibility_scores = []\n",
        "\n",
        "    for _, profile in profiles_df.iterrows():\n",
        "        profile_scores = []\n",
        "        profile_skills = set(profile['extracted_skills'])\n",
        "\n",
        "        for _, job in jobs_df.iterrows():\n",
        "            job_skills = set(job['extracted_skills'])\n",
        "\n",
        "            # Calculate base compatibility\n",
        "            if len(profile_skills) > 0 and len(job_skills) > 0:\n",
        "                skill_overlap = len(profile_skills.intersection(job_skills))\n",
        "                total_skills = len(profile_skills.union(job_skills))\n",
        "                base_score = skill_overlap / total_skills if total_skills > 0 else 0\n",
        "            else:\n",
        "                base_score = 0\n",
        "\n",
        "            # Add model-specific adjustments\n",
        "            if model_type == \"GAT\":\n",
        "                # GAT considers attention weights - simulate with location matching\n",
        "                location_boost = 0.1 if (\n",
        "                    pd.notna(profile.get('city')) and\n",
        "                    pd.notna(job.get('location')) and\n",
        "                    str(profile.get('city', '')).lower() in str(job.get('location', '')).lower()\n",
        "                ) else 0\n",
        "                final_score = min(base_score + location_boost + np.random.normal(0, 0.05), 1.0)\n",
        "            else:\n",
        "                # Standard GNN\n",
        "                final_score = min(base_score + np.random.normal(0, 0.03), 1.0)\n",
        "\n",
        "            final_score = max(0, final_score)  # Ensure non-negative\n",
        "            profile_scores.append(final_score)\n",
        "\n",
        "        compatibility_scores.append(profile_scores)\n",
        "\n",
        "    return np.array(compatibility_scores)\n",
        "\n",
        "def cluster_jobs_by_skills(jobs_df, n_clusters=5, detect_outliers=True):\n",
        "    \"\"\"Clustering jobs berdasarkan skills dengan deteksi outlier\"\"\"\n",
        "    # Prepare text data for clustering\n",
        "    job_texts = []\n",
        "    for _, job in jobs_df.iterrows():\n",
        "        skills_text = ' '.join(job['extracted_skills'])\n",
        "        job_text = f\"{job['title']} {skills_text} {job.get('formatted_work_type', '')}\"\n",
        "        job_texts.append(job_text)\n",
        "\n",
        "    # TF-IDF Vectorization\n",
        "    vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
        "    try:\n",
        "        X = vectorizer.fit_transform(job_texts)\n",
        "\n",
        "        # K-means clustering\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "        clusters = kmeans.fit_predict(X)\n",
        "\n",
        "        # TAMBAHAN: Deteksi outlier berdasarkan jarak ke centroid\n",
        "        outliers = []\n",
        "        if detect_outliers:\n",
        "            # Hitung jarak setiap titik ke centroid cluster-nya\n",
        "            distances = []\n",
        "            for i, point in enumerate(X.toarray()):\n",
        "                cluster_center = kmeans.cluster_centers_[clusters[i]]\n",
        "                distance = np.linalg.norm(point - cluster_center)\n",
        "                distances.append(distance)\n",
        "\n",
        "            distances = np.array(distances)\n",
        "\n",
        "            # Outlier detection menggunakan IQR method\n",
        "            Q1 = np.percentile(distances, 25)\n",
        "            Q3 = np.percentile(distances, 75)\n",
        "            IQR = Q3 - Q1\n",
        "            outlier_threshold = Q3 + 0.4 * IQR\n",
        "\n",
        "            outliers = distances > outlier_threshold\n",
        "            # outlier_threshold = np.percentile(distances, 95)\n",
        "            # outliers = distances > outlier_threshold\n",
        "\n",
        "        return clusters, vectorizer.get_feature_names_out(), outliers, distances if detect_outliers else None\n",
        "    except:\n",
        "        # Fallback if TF-IDF fails\n",
        "        n_jobs = len(jobs_df)\n",
        "        return np.random.randint(0, n_clusters, n_jobs), [], np.array([False] * n_jobs), None\n",
        "\n",
        "def run_batch_clustering_analysis(jobs_df, all_skills, test_configs):\n",
        "    \"\"\"Menjalankan batch clustering analysis dengan berbagai konfigurasi\"\"\"\n",
        "    results = []\n",
        "\n",
        "    for i, config in enumerate(test_configs):\n",
        "        n_clusters = config['n_clusters']\n",
        "        min_similarity = config['min_similarity']\n",
        "        model_type = config.get('model', 'GNN')\n",
        "\n",
        "        try:\n",
        "            # Clustering\n",
        "            clusters, feature_names, outliers, distances = cluster_jobs_by_skills(\n",
        "                jobs_df, n_clusters, detect_outliers=True\n",
        "            )\n",
        "\n",
        "            # Calculate metrics\n",
        "            n_outliers = sum(outliers)\n",
        "            outlier_percentage = (n_outliers / len(jobs_df)) * 100\n",
        "            avg_distance = np.mean(distances) if distances is not None else 0\n",
        "\n",
        "            # Calculate similarity matrix\n",
        "            similarity_matrix = calculate_job_similarity_matrix(jobs_df, all_skills)\n",
        "\n",
        "            # Network statistics\n",
        "            G = nx.Graph()\n",
        "            for idx, job in jobs_df.iterrows():\n",
        "                G.add_node(idx, cluster=clusters[idx])\n",
        "\n",
        "            # Add edges based on similarity\n",
        "            edges_added = 0\n",
        "            for i in range(len(jobs_df)):\n",
        "                for j in range(i+1, len(jobs_df)):\n",
        "                    if similarity_matrix[i][j] > min_similarity:\n",
        "                        G.add_edge(i, j, weight=similarity_matrix[i][j])\n",
        "                        edges_added += 1\n",
        "\n",
        "            avg_degree = sum(dict(G.degree()).values()) / G.number_of_nodes() if G.number_of_nodes() > 0 else 0\n",
        "\n",
        "            # Cluster distribution\n",
        "            cluster_dist = pd.Series(clusters).value_counts()\n",
        "            cluster_balance = cluster_dist.std() / cluster_dist.mean() if cluster_dist.mean() > 0 else 0\n",
        "\n",
        "            # Store results\n",
        "            result = {\n",
        "                'test_id': i + 1,\n",
        "                'n_clusters': n_clusters,\n",
        "                'min_similarity': min_similarity,\n",
        "                'model': model_type,\n",
        "                'total_outliers': n_outliers,\n",
        "                'outlier_percentage': outlier_percentage,\n",
        "                'avg_distance_to_centroid': avg_distance,\n",
        "                'network_nodes': G.number_of_nodes(),\n",
        "                'network_edges': edges_added,\n",
        "                'avg_connections': avg_degree,\n",
        "                'cluster_balance_score': cluster_balance,\n",
        "                'largest_cluster_size': cluster_dist.max(),\n",
        "                'smallest_cluster_size': cluster_dist.min(),\n",
        "                'clusters': clusters,\n",
        "                'outliers': outliers,\n",
        "                'distances': distances,\n",
        "                'similarity_matrix': similarity_matrix\n",
        "            }\n",
        "\n",
        "            results.append(result)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle errors gracefully\n",
        "            result = {\n",
        "                'test_id': i + 1,\n",
        "                'n_clusters': n_clusters,\n",
        "                'min_similarity': min_similarity,\n",
        "                'model': model_type,\n",
        "                'error': str(e),\n",
        "                'total_outliers': 0,\n",
        "                'outlier_percentage': 0,\n",
        "                'avg_distance_to_centroid': 0,\n",
        "                'network_nodes': 0,\n",
        "                'network_edges': 0,\n",
        "                'avg_connections': 0,\n",
        "                'cluster_balance_score': 0,\n",
        "                'largest_cluster_size': 0,\n",
        "                'smallest_cluster_size': 0\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Sidebar untuk navigasi\n",
        "st.sidebar.title(\"üîó Job Matching System\")\n",
        "st.sidebar.markdown(\"### Navigation\")\n",
        "\n",
        "page = st.sidebar.selectbox(\n",
        "    \"Choose Page\",\n",
        "    [\"Dashboard Overview\", \"Job Matching\", \"Graph Analysis\", \"Model Comparison\", \"Data Explorer\"]\n",
        ")\n",
        "\n",
        "# Model selection\n",
        "st.sidebar.markdown(\"### Model Selection\")\n",
        "selected_model = st.sidebar.selectbox(\n",
        "    \"Choose Model\",\n",
        "    [\"GNN\", \"GAT\"],\n",
        "    help=\"GNN: Graph Neural Network, GAT: Graph Attention Network\"\n",
        ")\n",
        "\n",
        "# Load data\n",
        "profiles_df, jobs_df = load_datasets()\n",
        "\n",
        "if profiles_df is not None and jobs_df is not None:\n",
        "    # Process data\n",
        "    profiles_df, jobs_df, all_skills = process_data_for_matching(profiles_df, jobs_df)\n",
        "\n",
        "    # Main content based on selected page\n",
        "    if page == \"Dashboard Overview\":\n",
        "        # Enhanced Page Header\n",
        "        st.markdown(\"\"\"\n",
        "        <div class=\"page-header\">\n",
        "            <div class=\"page-title\">üîó Job Matching Dashboard</div>\n",
        "            <div class=\"page-subtitle\">Powered by Graph Neural Networks & Graph Attention Networks</div>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        # Enhanced Key Metrics dengan Icons\n",
        "        col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "        with col1:\n",
        "            st.markdown(create_metric_card(\"Total Profiles\", len(profiles_df), \"üë•\"), unsafe_allow_html=True)\n",
        "        with col2:\n",
        "            st.markdown(create_metric_card(\"Total Jobs\", len(jobs_df), \"üíº\"), unsafe_allow_html=True)\n",
        "        with col3:\n",
        "            st.markdown(create_metric_card(\"Unique Skills\", len(all_skills), \"üéØ\"), unsafe_allow_html=True)\n",
        "        with col4:\n",
        "            active_jobs = len(jobs_df[jobs_df['expiry'] > datetime.now().timestamp()])\n",
        "            st.markdown(create_metric_card(\"Active Jobs\", active_jobs, \"‚úÖ\"), unsafe_allow_html=True)\n",
        "\n",
        "        # Charts\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.subheader(\"Job Distribution by Work Type\")\n",
        "            work_type_counts = jobs_df['formatted_work_type'].value_counts()\n",
        "            fig_work_type = px.pie(\n",
        "                values=work_type_counts.values,\n",
        "                names=work_type_counts.index,\n",
        "                title=\"Job Work Types\"\n",
        "            )\n",
        "            st.plotly_chart(fig_work_type, use_container_width=True)\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"Top Skills in Job Market\")\n",
        "            all_job_skills = []\n",
        "            for skills in jobs_df['extracted_skills']:\n",
        "                all_job_skills.extend(skills)\n",
        "\n",
        "            if all_job_skills:\n",
        "                skill_counts = pd.Series(all_job_skills).value_counts().head(10)\n",
        "                fig_skills = px.bar(\n",
        "                    x=skill_counts.values,\n",
        "                    y=skill_counts.index,\n",
        "                    orientation='h',\n",
        "                    title=\"Most Demanded Skills\"\n",
        "                )\n",
        "                fig_skills.update_layout(yaxis={'categoryorder':'total ascending'})\n",
        "                st.plotly_chart(fig_skills, use_container_width=True)\n",
        "\n",
        "        # Geographic distribution\n",
        "        st.subheader(\"Geographic Distribution\")\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.write(\"**Profile Locations**\")\n",
        "            if 'country_code' in profiles_df.columns:\n",
        "                country_counts = profiles_df['country_code'].value_counts().head(10)\n",
        "                fig_countries = px.bar(\n",
        "                    x=country_counts.index,\n",
        "                    y=country_counts.values,\n",
        "                    title=\"Profiles by Country\"\n",
        "                )\n",
        "                st.plotly_chart(fig_countries, use_container_width=True)\n",
        "\n",
        "        with col2:\n",
        "            st.write(\"**Job Locations**\")\n",
        "            # Extract city from location\n",
        "            jobs_df['job_city'] = jobs_df['location'].str.split(',').str[0]\n",
        "            city_counts = jobs_df['job_city'].value_counts().head(10)\n",
        "            fig_job_cities = px.bar(\n",
        "                x=city_counts.index,\n",
        "                y=city_counts.values,\n",
        "                title=\"Jobs by City\"\n",
        "            )\n",
        "            fig_job_cities.update_xaxes(tickangle=45)\n",
        "            st.plotly_chart(fig_job_cities, use_container_width=True)\n",
        "\n",
        "    elif page == \"Job Matching\":\n",
        "        st.title(\"üéØ Job Matching System\")\n",
        "        st.write(f\"Using **{selected_model}** model for predictions\")\n",
        "\n",
        "        # Profile selection\n",
        "        st.subheader(\"Select Profile for Matching\")\n",
        "\n",
        "        # Profile search and filter\n",
        "        col1, col2 = st.columns([2, 1])\n",
        "        with col1:\n",
        "            search_name = st.text_input(\"Search by name:\", \"\")\n",
        "        with col2:\n",
        "            position_filter = st.selectbox(\n",
        "                \"Filter by position:\",\n",
        "                [\"All\"] + list(profiles_df['position'].dropna().unique()[:20])\n",
        "            )\n",
        "\n",
        "        # Filter profiles\n",
        "        filtered_profiles = profiles_df.copy()\n",
        "        if search_name:\n",
        "            filtered_profiles = filtered_profiles[\n",
        "                filtered_profiles['name'].str.contains(search_name, case=False, na=False)\n",
        "            ]\n",
        "        if position_filter != \"All\":\n",
        "            filtered_profiles = filtered_profiles[\n",
        "                filtered_profiles['position'] == position_filter\n",
        "            ]\n",
        "\n",
        "        if len(filtered_profiles) > 0:\n",
        "            selected_profile_idx = st.selectbox(\n",
        "                \"Choose profile:\",\n",
        "                range(len(filtered_profiles)),\n",
        "                format_func=lambda x: f\"{filtered_profiles.iloc[x]['name']} - {filtered_profiles.iloc[x]['position']}\"\n",
        "            )\n",
        "\n",
        "            selected_profile = filtered_profiles.iloc[selected_profile_idx]\n",
        "\n",
        "            st.subheader(\"Additional Information\")\n",
        "            col1, col2 = st.columns(2)\n",
        "            with col1:\n",
        "                location = st.text_input(\"Location:\", selected_profile.get('city', ''))\n",
        "                expected_salary = st.text_input(\"Certifications:\", selected_profile.get('certifications', ''))\n",
        "                experience = st.text_input(\"Experience:\", selected_profile.get('experience', ''))\n",
        "            with col2:\n",
        "                education = st.text_input(\"Education:\", selected_profile.get('education', ''))\n",
        "                languages = st.text_input(\"Languages:\", selected_profile.get('languages', ''))\n",
        "                about = st.text_area(\"About:\", selected_profile.get('about', ''))\n",
        "\n",
        "            # Display profile info\n",
        "            st.markdown(\"### Selected Profile\")\n",
        "            col1, col2 = st.columns([1, 2])\n",
        "\n",
        "            with col1:\n",
        "                st.markdown(f\"\"\"\n",
        "                <div class=\"profile-card\">\n",
        "                <h4>{selected_profile['name']}</h4>\n",
        "                <p><strong>Position:</strong> {selected_profile['position']}</p>\n",
        "                <p><strong>Company:</strong> {selected_profile.get('current_company:name', 'N/A')}</p>\n",
        "                <p><strong>Location:</strong> {selected_profile.get('city', 'N/A')}</p>\n",
        "                </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            with col2:\n",
        "                st.write(\"**Skills:**\")\n",
        "                profile_skills = selected_profile['extracted_skills']\n",
        "                if profile_skills:\n",
        "                    skills_text = \", \".join(profile_skills)\n",
        "                    st.write(skills_text)\n",
        "                else:\n",
        "                    st.write(\"No skills extracted\")\n",
        "\n",
        "            # Model Performance Indicator\n",
        "            st.markdown(\"### ü§ñ Model Status\")\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                if selected_model == \"GNN\":\n",
        "                    st.markdown(create_status_badge(\"active\", \"GNN Active\"), unsafe_allow_html=True)\n",
        "                else:\n",
        "                    st.markdown(create_status_badge(\"inactive\", \"GNN Inactive\"), unsafe_allow_html=True)\n",
        "            with col2:\n",
        "                if selected_model == \"GAT\":\n",
        "                    st.markdown(create_status_badge(\"active\", \"GAT Active\"), unsafe_allow_html=True)\n",
        "                else:\n",
        "                    st.markdown(create_status_badge(\"inactive\", \"GAT Inactive\"), unsafe_allow_html=True)\n",
        "            with col3:\n",
        "                st.markdown(create_status_badge(\"pending\", \"Training Ready\"), unsafe_allow_html=True)\n",
        "\n",
        "            # Generate predictions\n",
        "            if st.button(\"Find Matching Jobs\", type=\"primary\"):\n",
        "                with st.spinner(f'Finding matches using {selected_model}...'):\n",
        "                    # Get profile index in original dataframe\n",
        "                    profile_original_idx = profiles_df[profiles_df['id'] == selected_profile['id']].index[0]\n",
        "\n",
        "                    # Calculate compatibility scores\n",
        "                    compatibility_scores = simulate_gnn_predictions(\n",
        "                        profiles_df, jobs_df, all_skills, selected_model\n",
        "                    )\n",
        "\n",
        "                    # Get scores for selected profile\n",
        "                    profile_scores = compatibility_scores[profile_original_idx]\n",
        "\n",
        "                    # Create results dataframe\n",
        "                    results_df = jobs_df.copy()\n",
        "                    results_df['compatibility_score'] = profile_scores\n",
        "                    results_df = results_df.sort_values('compatibility_score', ascending=False)\n",
        "\n",
        "                    # Display top matches\n",
        "                    st.subheader(f\"Top Job Matches (Using {selected_model})\")\n",
        "\n",
        "                    top_matches = results_df.head(10)\n",
        "\n",
        "                    for idx, (_, job) in enumerate(top_matches.iterrows()):\n",
        "                        score = job['compatibility_score']\n",
        "\n",
        "                        # Color coding based on score\n",
        "                        if score >= 0.7:\n",
        "                            score_color = \"üü¢\"\n",
        "                        elif score >= 0.5:\n",
        "                            score_color = \"üü°\"\n",
        "                        else:\n",
        "                            score_color = \"üî¥\"\n",
        "\n",
        "                        st.markdown(f\"\"\"\n",
        "                        <div class=\"job-card\">\n",
        "                        <h4>{score_color} {job['title']} - {job.get('company_name', 'Unknown Company')}</h4>\n",
        "                        <p><strong>Compatibility Score:</strong> {score:.3f}</p>\n",
        "                        <p><strong>Location:</strong> {job['location']}</p>\n",
        "                        <p><strong>Work Type:</strong> {job['formatted_work_type']}</p>\n",
        "                        <p><strong>Required Skills:</strong> {', '.join(job['extracted_skills'][:5]) if job['extracted_skills'] else 'No specific skills listed'}</p>\n",
        "                        <p><strong>Description:</strong> {job['description'][:200]}...</p>\n",
        "                        </div>\n",
        "                        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                    # Score distribution\n",
        "                    st.subheader(\"Score Distribution\")\n",
        "                    fig_scores = px.histogram(\n",
        "                        profile_scores,\n",
        "                        nbins=20,\n",
        "                        title=f\"Distribution of Compatibility Scores ({selected_model})\"\n",
        "                    )\n",
        "                    fig_scores.update_xaxes(title=\"Compatibility Score\")\n",
        "                    fig_scores.update_yaxes(title=\"Number of Jobs\")\n",
        "                    st.plotly_chart(fig_scores, use_container_width=True)\n",
        "\n",
        "        else:\n",
        "            st.warning(\"No profiles found matching the search criteria.\")\n",
        "\n",
        "    # MODIFIKASI: Ganti bagian \"Graph Analysis\" page dengan ini\n",
        "    elif page == \"Graph Analysis\":\n",
        "        st.title(\"üï∏Ô∏è Graph-based Job Clustering\")\n",
        "\n",
        "        # Pilihan mode analysis\n",
        "        analysis_mode = st.radio(\n",
        "            \"Choose Analysis Mode\",\n",
        "            [\"Single Test\", \"Batch Testing\"],\n",
        "            horizontal=True\n",
        "        )\n",
        "\n",
        "        if analysis_mode == \"Single Test\":\n",
        "            # KODE SINGLE TEST YANG SUDAH ADA (tidak berubah)\n",
        "            st.subheader(\"Job Clustering Analysis\")\n",
        "\n",
        "            # Clustering parameters\n",
        "            col1, col2 = st.columns(2)\n",
        "            with col1:\n",
        "                n_clusters = st.slider(\"Number of Clusters\", 3, 10, 5)\n",
        "            with col2:\n",
        "                min_similarity = st.slider(\"Minimum Similarity Threshold\", 0.0, 1.0, 0.3)\n",
        "\n",
        "            if st.button(\"Generate Job Clusters\", type=\"primary\"):\n",
        "                with st.spinner(\"Clustering jobs based on skills...\"):\n",
        "                    # UBAH PEMANGGILAN FUNGSI INI\n",
        "                    clusters, feature_names, outliers, distances = cluster_jobs_by_skills(jobs_df, n_clusters, detect_outliers=True)\n",
        "                    jobs_df['cluster'] = clusters\n",
        "                    jobs_df['is_outlier'] = outliers\n",
        "                    if distances is not None:\n",
        "                        jobs_df['distance_to_centroid'] = distances\n",
        "\n",
        "                    # Calculate similarity matrix\n",
        "                    similarity_matrix = calculate_job_similarity_matrix(jobs_df, all_skills)\n",
        "\n",
        "                    # TAMBAHAN: Display outlier summary\n",
        "                    st.subheader(\"Outlier Analysis\")\n",
        "                    n_outliers = sum(outliers)\n",
        "                    col1, col2, col3 = st.columns(3)\n",
        "                    with col1:\n",
        "                        st.metric(\"Total Outliers\", n_outliers)\n",
        "                    with col2:\n",
        "                        outlier_percentage = (n_outliers / len(jobs_df)) * 100\n",
        "                        st.metric(\"Outlier Percentage\", f\"{outlier_percentage:.1f}%\")\n",
        "                    with col3:\n",
        "                        if distances is not None:\n",
        "                            avg_distance = np.mean(distances)\n",
        "                            st.metric(\"Avg Distance to Centroid\", f\"{avg_distance:.3f}\")\n",
        "\n",
        "                    # TAMBAHAN: Show outlier jobs\n",
        "                    if n_outliers > 0:\n",
        "                        with st.expander(f\"View Outlier Jobs ({n_outliers} jobs)\"):\n",
        "                            outlier_jobs = jobs_df[jobs_df['is_outlier'] == True][['title', 'company_name', 'extracted_skills', 'distance_to_centroid']].head(10)\n",
        "                            st.dataframe(outlier_jobs)\n",
        "\n",
        "                    # Display cluster summary\n",
        "                    st.subheader(\"Cluster Summary\")\n",
        "                    cluster_summary = jobs_df.groupby('cluster').agg({\n",
        "                        'title': 'count',\n",
        "                        'formatted_work_type': lambda x: x.mode()[0] if not x.empty else 'N/A',\n",
        "                        'extracted_skills': lambda x: list(set([skill for skills in x for skill in skills]))\n",
        "                    }).rename(columns={'title': 'job_count'})\n",
        "\n",
        "                    for cluster_id in range(n_clusters):\n",
        "                        if cluster_id in cluster_summary.index:\n",
        "                            cluster_info = cluster_summary.loc[cluster_id]\n",
        "\n",
        "                            with st.expander(f\"Cluster {cluster_id} ({cluster_info['job_count']} jobs)\"):\n",
        "                                st.write(f\"**Dominant Work Type:** {cluster_info['formatted_work_type']}\")\n",
        "                                st.write(f\"**Common Skills:** {', '.join(cluster_info['extracted_skills'][:10])}\")\n",
        "\n",
        "                                # Show sample jobs from cluster\n",
        "                                cluster_jobs = jobs_df[jobs_df['cluster'] == cluster_id].head(5)\n",
        "                                st.write(\"**Sample Jobs:**\")\n",
        "                                for _, job in cluster_jobs.iterrows():\n",
        "                                    st.write(f\"‚Ä¢ {job['title']} at {job.get('company_name', 'Unknown')}\")\n",
        "\n",
        "                    # BAGIAN YANG DIUBAH: Cluster Visualization dengan PCA\n",
        "                    st.subheader(\"Cluster Visualization\")\n",
        "\n",
        "                    # Prepare feature matrix for PCA\n",
        "                    try:\n",
        "                        # Create TF-IDF matrix for jobs\n",
        "                        job_texts = []\n",
        "                        for _, job in jobs_df.iterrows():\n",
        "                            skills_text = ' '.join(job['extracted_skills'])\n",
        "                            job_text = f\"{job['title']} {skills_text} {job.get('formatted_work_type', '')}\"\n",
        "                            job_texts.append(job_text)\n",
        "\n",
        "                        # TF-IDF Vectorization\n",
        "                        vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
        "                        X_tfidf = vectorizer.fit_transform(job_texts)\n",
        "\n",
        "                        # Convert to dense array\n",
        "                        X_dense = X_tfidf.toarray()\n",
        "\n",
        "                        # Standardize features\n",
        "                        scaler = StandardScaler()\n",
        "                        X_scaled = scaler.fit_transform(X_dense)\n",
        "\n",
        "                        # Apply PCA\n",
        "                        pca = PCA(n_components=2)\n",
        "                        X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "                        # Create DataFrame for visualization\n",
        "                        pca_df = pd.DataFrame({\n",
        "                            'PC1': X_pca[:, 0],\n",
        "                            'PC2': X_pca[:, 1],\n",
        "                            'Cluster': jobs_df['cluster'].values,\n",
        "                            'Job_Title': jobs_df['title'].values,\n",
        "                            'Company': jobs_df.get('company_name', 'Unknown').values,\n",
        "                            'Work_Type': jobs_df['formatted_work_type'].values,\n",
        "                            'Is_Outlier': jobs_df['is_outlier'].values,  # TAMBAHAN\n",
        "                            'Distance': jobs_df.get('distance_to_centroid', 0).values  # TAMBAHAN\n",
        "                        })\n",
        "\n",
        "                        # Create scatter plot\n",
        "                        fig_pca = px.scatter(\n",
        "                            pca_df,\n",
        "                            x='PC1',\n",
        "                            y='PC2',\n",
        "                            color='Cluster',\n",
        "                            symbol='Is_Outlier',  # TAMBAHAN: berbeda symbol untuk outlier\n",
        "                            size='Distance',      # TAMBAHAN: size berdasarkan jarak ke centroid\n",
        "                            hover_data=['Job_Title', 'Company', 'Work_Type', 'Distance'],\n",
        "                            title=f\"Job Clusters with Outliers (PCA) - {n_clusters} Clusters\",\n",
        "                            labels={\n",
        "                                'PC1': f'First Principal Component ({pca.explained_variance_ratio_[0]:.2%} variance)',\n",
        "                                'PC2': f'Second Principal Component ({pca.explained_variance_ratio_[1]:.2%} variance)'\n",
        "                            },\n",
        "                            color_continuous_scale='viridis',\n",
        "                            symbol_map={True: 'diamond', False: 'circle'}  # TAMBAHAN: diamond untuk outlier\n",
        "                        )\n",
        "\n",
        "                        # Update layout for better visualization\n",
        "                        fig_pca.update_traces(marker=dict(opacity=0.7, line=dict(width=1, color='white')))\n",
        "                        fig_pca.update_layout(\n",
        "                            width=800,\n",
        "                            height=600,\n",
        "                            showlegend=True,\n",
        "                            legend=dict(\n",
        "                                title=\"Legend\",\n",
        "                                orientation=\"v\",\n",
        "                                yanchor=\"top\",\n",
        "                                y=1,\n",
        "                                xanchor=\"left\",\n",
        "                                x=1.01\n",
        "                            )\n",
        "                        )\n",
        "\n",
        "                        st.plotly_chart(fig_pca, use_container_width=True)\n",
        "\n",
        "                        # PCA Analysis Information\n",
        "                        col1, col2, col3 = st.columns(3)\n",
        "                        with col1:\n",
        "                            st.metric(\"Total Variance Explained\", f\"{sum(pca.explained_variance_ratio_):.2%}\")\n",
        "                        with col2:\n",
        "                            st.metric(\"PC1 Variance\", f\"{pca.explained_variance_ratio_[0]:.2%}\")\n",
        "                        with col3:\n",
        "                            st.metric(\"PC2 Variance\", f\"{pca.explained_variance_ratio_[1]:.2%}\")\n",
        "\n",
        "                        # Feature importance in PCA\n",
        "                        st.subheader(\"PCA Component Analysis\")\n",
        "\n",
        "                        # Get feature names\n",
        "                        feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "                        # PC1 top features\n",
        "                        pc1_features = pd.DataFrame({\n",
        "                            'Feature': feature_names,\n",
        "                            'PC1_Weight': pca.components_[0]\n",
        "                        }).sort_values('PC1_Weight', key=abs, ascending=False).head(10)\n",
        "\n",
        "                        # PC2 top features\n",
        "                        pc2_features = pd.DataFrame({\n",
        "                            'Feature': feature_names,\n",
        "                            'PC2_Weight': pca.components_[1]\n",
        "                        }).sort_values('PC2_Weight', key=abs, ascending=False).head(10)\n",
        "\n",
        "                        col1, col2 = st.columns(2)\n",
        "                        with col1:\n",
        "                            st.write(\"**Top Features in PC1**\")\n",
        "                            fig_pc1 = px.bar(\n",
        "                                pc1_features,\n",
        "                                x='PC1_Weight',\n",
        "                                y='Feature',\n",
        "                                orientation='h',\n",
        "                                title=\"Most Important Features in PC1\"\n",
        "                            )\n",
        "                            fig_pc1.update_layout(yaxis={'categoryorder':'total ascending'})\n",
        "                            st.plotly_chart(fig_pc1, use_container_width=True)\n",
        "\n",
        "                        with col2:\n",
        "                            st.write(\"**Top Features in PC2**\")\n",
        "                            fig_pc2 = px.bar(\n",
        "                                pc2_features,\n",
        "                                x='PC2_Weight',\n",
        "                                y='Feature',\n",
        "                                orientation='h',\n",
        "                                title=\"Most Important Features in PC2\"\n",
        "                            )\n",
        "                            fig_pc2.update_layout(yaxis={'categoryorder':'total ascending'})\n",
        "                            st.plotly_chart(fig_pc2, use_container_width=True)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Error in PCA visualization: {str(e)}\")\n",
        "                        st.info(\"Falling back to cluster distribution chart...\")\n",
        "\n",
        "                        # Fallback: Original cluster distribution chart\n",
        "                        cluster_dist = jobs_df['cluster'].value_counts().sort_index()\n",
        "                        fig_clusters = px.bar(\n",
        "                            x=cluster_dist.index,\n",
        "                            y=cluster_dist.values,\n",
        "                            title=\"Jobs per Cluster\",\n",
        "                            labels={'x': 'Cluster ID', 'y': 'Number of Jobs'}\n",
        "                        )\n",
        "                        st.plotly_chart(fig_clusters, use_container_width=True)\n",
        "\n",
        "                    # Network statistics (tetap dipertahankan)\n",
        "                    st.subheader(\"Network Statistics\")\n",
        "\n",
        "                    # Create network graph\n",
        "                    G = nx.Graph()\n",
        "\n",
        "                    # Add nodes (jobs)\n",
        "                    for idx, job in jobs_df.iterrows():\n",
        "                        company = str(job.get('company_name', 'Unknown'))[:20]\n",
        "                        G.add_node(idx,\n",
        "                                title=job['title'][:30],\n",
        "                                cluster=job['cluster'],\n",
        "                                company=company)\n",
        "\n",
        "                    # Add edges based on similarity\n",
        "                    for i in range(len(jobs_df)):\n",
        "                        for j in range(i+1, len(jobs_df)):\n",
        "                            if similarity_matrix[i][j] > min_similarity:\n",
        "                                G.add_edge(i, j, weight=similarity_matrix[i][j])\n",
        "\n",
        "                    # Network statistics\n",
        "                    col1, col2, col3 = st.columns(3)\n",
        "                    with col1:\n",
        "                        st.metric(\"Nodes (Jobs)\", G.number_of_nodes())\n",
        "                    with col2:\n",
        "                        st.metric(\"Edges (Connections)\", G.number_of_edges())\n",
        "                    with col3:\n",
        "                        avg_degree = sum(dict(G.degree()).values()) / G.number_of_nodes() if G.number_of_nodes() > 0 else 0\n",
        "                        st.metric(\"Avg Connections\", f\"{avg_degree:.2f}\")\n",
        "\n",
        "                    # Cluster distribution chart\n",
        "                    cluster_dist = jobs_df['cluster'].value_counts().sort_index()\n",
        "                    fig_clusters = px.bar(\n",
        "                        x=cluster_dist.index,\n",
        "                        y=cluster_dist.values,\n",
        "                        title=\"Jobs per Cluster\",\n",
        "                        labels={'x': 'Cluster ID', 'y': 'Number of Jobs'}\n",
        "                    )\n",
        "                    st.plotly_chart(fig_clusters, use_container_width=True)\n",
        "\n",
        "                    # TAMBAHAN: Outlier distribution chart\n",
        "                    st.subheader(\"Outlier Distribution by Cluster\")\n",
        "                    outlier_by_cluster = jobs_df.groupby('cluster')['is_outlier'].agg(['sum', 'count']).reset_index()\n",
        "                    outlier_by_cluster['outlier_percentage'] = (outlier_by_cluster['sum'] / outlier_by_cluster['count']) * 100\n",
        "\n",
        "                    fig_outlier_dist = px.bar(\n",
        "                        outlier_by_cluster,\n",
        "                        x='cluster',\n",
        "                        y='outlier_percentage',\n",
        "                        title=\"Percentage of Outliers by Cluster\",\n",
        "                        labels={'cluster': 'Cluster ID', 'outlier_percentage': 'Outlier Percentage (%)'}\n",
        "                    )\n",
        "                    st.plotly_chart(fig_outlier_dist, use_container_width=True)\n",
        "\n",
        "                    # TAMBAHAN: Distance distribution\n",
        "                    if distances is not None:\n",
        "                        st.subheader(\"Distance to Centroid Distribution\")\n",
        "                        fig_distance = px.histogram(\n",
        "                            jobs_df,\n",
        "                            x='distance_to_centroid',\n",
        "                            color='is_outlier',\n",
        "                            title=\"Distribution of Distances to Cluster Centroids\",\n",
        "                            labels={'distance_to_centroid': 'Distance to Centroid', 'count': 'Number of Jobs'},\n",
        "                            nbins=30\n",
        "                        )\n",
        "                        st.plotly_chart(fig_distance, use_container_width=True)\n",
        "\n",
        "        else:  # Batch Testing Mode\n",
        "            st.subheader(\"üöÄ Batch Testing Configuration\")\n",
        "\n",
        "            # Batch configuration\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                num_tests = st.number_input(\"Number of Tests\", min_value=2, max_value=10, value=3)\n",
        "                st.info(f\"Configure {num_tests} different test scenarios\")\n",
        "\n",
        "            with col2:\n",
        "                default_model = st.selectbox(\"Default Model for All Tests\", [\"GNN\", \"GAT\"])\n",
        "                allow_model_selection = st.checkbox(\"Allow different models per test\")\n",
        "\n",
        "            # Dynamic test configuration\n",
        "            st.subheader(\"Test Configurations\")\n",
        "            test_configs = []\n",
        "\n",
        "            # Create tabs for each test\n",
        "            tab_labels = [f\"Test {i+1}\" for i in range(num_tests)]\n",
        "            tabs = st.tabs(tab_labels)\n",
        "\n",
        "            for i, tab in enumerate(tabs):\n",
        "                with tab:\n",
        "                    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "                    with col1:\n",
        "                        clusters = st.slider(\n",
        "                            f\"Number of Clusters\",\n",
        "                            3, 10, 5,\n",
        "                            key=f\"clusters_{i}\"\n",
        "                        )\n",
        "\n",
        "                    with col2:\n",
        "                        similarity = st.slider(\n",
        "                            f\"Min Similarity Threshold\",\n",
        "                            0.0, 1.0, 0.3,\n",
        "                            key=f\"similarity_{i}\"\n",
        "                        )\n",
        "\n",
        "                    with col3:\n",
        "                        if allow_model_selection:\n",
        "                            model = st.selectbox(\n",
        "                                \"Model\",\n",
        "                                [\"GNN\", \"GAT\"],\n",
        "                                index=0 if default_model == \"GNN\" else 1,\n",
        "                                key=f\"model_{i}\"\n",
        "                            )\n",
        "                        else:\n",
        "                            model = default_model\n",
        "                            st.write(f\"**Model:** {model}\")\n",
        "\n",
        "                    test_configs.append({\n",
        "                        'n_clusters': clusters,\n",
        "                        'min_similarity': similarity,\n",
        "                        'model': model\n",
        "                    })\n",
        "\n",
        "            # Run batch analysis\n",
        "            if st.button(\"üöÄ Run Batch Analysis\", type=\"primary\", use_container_width=True):\n",
        "                # Progress tracking\n",
        "                progress_bar = st.progress(0)\n",
        "                status_text = st.empty()\n",
        "\n",
        "                with st.spinner(\"Running batch clustering analysis...\"):\n",
        "                    # Run batch analysis\n",
        "                    batch_results = run_batch_clustering_analysis(jobs_df, all_skills, test_configs)\n",
        "\n",
        "                    # Update progress\n",
        "                    progress_bar.progress(100)\n",
        "                    status_text.success(f\"‚úÖ Completed {len(batch_results)} tests!\")\n",
        "\n",
        "                # Display results comparison\n",
        "                st.subheader(\"üìä Batch Results Comparison\")\n",
        "\n",
        "                # Results summary table\n",
        "                results_df = pd.DataFrame([\n",
        "                    {\n",
        "                        'Test ID': r['test_id'],\n",
        "                        'Clusters': r['n_clusters'],\n",
        "                        'Min Similarity': r['min_similarity'],\n",
        "                        'Model': r['model'],\n",
        "                        'Outliers': r['total_outliers'],\n",
        "                        'Outlier %': f\"{r['outlier_percentage']:.1f}%\",\n",
        "                        'Avg Distance': f\"{r['avg_distance_to_centroid']:.3f}\",\n",
        "                        'Network Edges': r['network_edges'],\n",
        "                        'Avg Connections': f\"{r['avg_connections']:.2f}\",\n",
        "                        'Cluster Balance': f\"{r['cluster_balance_score']:.3f}\",\n",
        "                        'Largest Cluster': r['largest_cluster_size'],\n",
        "                        'Smallest Cluster': r['smallest_cluster_size']\n",
        "                    }\n",
        "                    for r in batch_results if 'error' not in r\n",
        "                ])\n",
        "\n",
        "                if not results_df.empty:\n",
        "                    st.dataframe(results_df, use_container_width=True)\n",
        "\n",
        "                    # Comparison charts\n",
        "                    st.subheader(\"üìà Performance Comparison Charts\")\n",
        "\n",
        "                    # Create comparison metrics\n",
        "                    col1, col2 = st.columns(2)\n",
        "\n",
        "                    with col1:\n",
        "                        # Outlier comparison\n",
        "                        fig_outliers = px.bar(\n",
        "                            results_df,\n",
        "                            x='Test ID',\n",
        "                            y='Outliers',\n",
        "                            color='Model',\n",
        "                            title=\"Outliers Detected by Test\",\n",
        "                            text='Outliers'\n",
        "                        )\n",
        "                        fig_outliers.update_traces(textposition='outside')\n",
        "                        st.plotly_chart(fig_outliers, use_container_width=True)\n",
        "\n",
        "                    with col2:\n",
        "                        # Network connectivity comparison\n",
        "                        fig_connections = px.bar(\n",
        "                            results_df,\n",
        "                            x='Test ID',\n",
        "                            y='Network Edges',\n",
        "                            color='Model',\n",
        "                            title=\"Network Connections by Test\",\n",
        "                            text='Network Edges'\n",
        "                        )\n",
        "                        fig_connections.update_traces(textposition='outside')\n",
        "                        st.plotly_chart(fig_connections, use_container_width=True)\n",
        "\n",
        "                    # Cluster balance comparison\n",
        "                    fig_balance = px.line(\n",
        "                        results_df,\n",
        "                        x='Test ID',\n",
        "                        y='Cluster Balance',\n",
        "                        color='Model',\n",
        "                        title=\"Cluster Balance Score (Lower = More Balanced)\",\n",
        "                        markers=True\n",
        "                    )\n",
        "                    st.plotly_chart(fig_balance, use_container_width=True)\n",
        "\n",
        "                    # Best performing test\n",
        "                    st.subheader(\"üèÜ Best Performing Tests\")\n",
        "\n",
        "                    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "                    with col1:\n",
        "                        # Lowest outlier percentage\n",
        "                        best_outlier = results_df.loc[results_df['Outliers'].idxmin()]\n",
        "                        st.metric(\n",
        "                            \"Lowest Outliers\",\n",
        "                            f\"Test {best_outlier['Test ID']}\",\n",
        "                            f\"{best_outlier['Outliers']} outliers\"\n",
        "                        )\n",
        "\n",
        "                    with col2:\n",
        "                        # Best cluster balance\n",
        "                        best_balance = results_df.loc[results_df['Cluster Balance'].idxmin()]\n",
        "                        st.metric(\n",
        "                            \"Best Balance\",\n",
        "                            f\"Test {best_balance['Test ID']}\",\n",
        "                            f\"{float(best_balance['Cluster Balance']):.3f} score\"\n",
        "                        )\n",
        "\n",
        "                    with col3:\n",
        "                        # Highest connectivity\n",
        "                        best_connectivity = results_df.loc[results_df['Network Edges'].idxmax()]\n",
        "                        st.metric(\n",
        "                            \"Best Connectivity\",\n",
        "                            f\"Test {best_connectivity['Test ID']}\",\n",
        "                            f\"{best_connectivity['Network Edges']} edges\"\n",
        "                        )\n",
        "\n",
        "                    # Detailed results for each test\n",
        "                    st.subheader(\"üîç Detailed Test Results\")\n",
        "\n",
        "                    selected_test = st.selectbox(\n",
        "                        \"Select Test to View Details\",\n",
        "                        options=range(1, len(batch_results) + 1),\n",
        "                        format_func=lambda x: f\"Test {x} (Clusters: {test_configs[x-1]['n_clusters']}, \"\n",
        "                                            f\"Similarity: {test_configs[x-1]['min_similarity']}, \"\n",
        "                                            f\"Model: {test_configs[x-1]['model']})\"\n",
        "                    )\n",
        "\n",
        "                    if selected_test:\n",
        "                        selected_result = batch_results[selected_test - 1]\n",
        "\n",
        "                        if 'error' not in selected_result:\n",
        "                            # Create temporary dataframe with results for visualization\n",
        "                            temp_jobs_df = jobs_df.copy()\n",
        "                            temp_jobs_df['cluster'] = selected_result['clusters']\n",
        "                            temp_jobs_df['is_outlier'] = selected_result['outliers']\n",
        "                            if selected_result['distances'] is not None:\n",
        "                                temp_jobs_df['distance_to_centroid'] = selected_result['distances']\n",
        "\n",
        "                            # Show cluster distribution for selected test\n",
        "                            cluster_dist = pd.Series(selected_result['clusters']).value_counts().sort_index()\n",
        "                            fig_selected = px.bar(\n",
        "                                x=cluster_dist.index,\n",
        "                                y=cluster_dist.values,\n",
        "                                title=f\"Test {selected_test} - Jobs per Cluster\",\n",
        "                                labels={'x': 'Cluster ID', 'y': 'Number of Jobs'}\n",
        "                            )\n",
        "                            st.plotly_chart(fig_selected, use_container_width=True)\n",
        "\n",
        "                            # Show outlier information\n",
        "                            if selected_result['total_outliers'] > 0:\n",
        "                                outlier_jobs = temp_jobs_df[temp_jobs_df['is_outlier'] == True][\n",
        "                                    ['title', 'company_name', 'extracted_skills']\n",
        "                                ].head(5)\n",
        "\n",
        "                                st.write(f\"**Sample Outlier Jobs ({selected_result['total_outliers']} total):**\")\n",
        "                                st.dataframe(outlier_jobs, use_container_width=True)\n",
        "\n",
        "                        else:\n",
        "                            st.error(f\"Test {selected_test} failed with error: {selected_result['error']}\")\n",
        "\n",
        "                else:\n",
        "                    st.error(\"All tests failed. Please check your configurations and try again.\")\n",
        "\n",
        "    elif page == \"Model Comparison\":\n",
        "        st.title(\"‚öñÔ∏è GNN vs GAT Model Comparison\")\n",
        "\n",
        "        st.subheader(\"Model Performance Analysis\")\n",
        "\n",
        "        if st.button(\"Run Model Comparison\", type=\"primary\"):\n",
        "            with st.spinner(\"Comparing GNN and GAT models...\"):\n",
        "                # Generate predictions for both models\n",
        "                gnn_scores = simulate_gnn_predictions(profiles_df, jobs_df, all_skills, \"GNN\")\n",
        "                gat_scores = simulate_gnn_predictions(profiles_df, jobs_df, all_skills, \"GAT\")\n",
        "\n",
        "                # Calculate metrics\n",
        "                gnn_avg_scores = np.mean(gnn_scores, axis=1)\n",
        "                gat_avg_scores = np.mean(gat_scores, axis=1)\n",
        "\n",
        "                # Display comparison metrics\n",
        "                col1, col2 = st.columns(2)\n",
        "\n",
        "                with col1:\n",
        "                    st.metric(\"GNN Avg Score\", f\"{np.mean(gnn_avg_scores):.3f}\")\n",
        "                    st.metric(\"GNN Std Dev\", f\"{np.std(gnn_avg_scores):.3f}\")\n",
        "\n",
        "                with col2:\n",
        "                    st.metric(\"GAT Avg Score\", f\"{np.mean(gat_avg_scores):.3f}\")\n",
        "                    st.metric(\"GAT Std Dev\", f\"{np.std(gat_avg_scores):.3f}\")\n",
        "\n",
        "                # Score distribution comparison\n",
        "                fig_comparison = make_subplots(\n",
        "                    rows=1, cols=2,\n",
        "                    subplot_titles=(\"GNN Score Distribution\", \"GAT Score Distribution\")\n",
        "                )\n",
        "\n",
        "                fig_comparison.add_trace(\n",
        "                    go.Histogram(x=gnn_avg_scores, name=\"GNN\", nbinsx=20),\n",
        "                    row=1, col=1\n",
        "                )\n",
        "\n",
        "                fig_comparison.add_trace(\n",
        "                    go.Histogram(x=gat_avg_scores, name=\"GAT\", nbinsx=20),\n",
        "                    row=1, col=2\n",
        "                )\n",
        "\n",
        "                fig_comparison.update_layout(\n",
        "                    title_text=\"Model Score Distribution Comparison\",\n",
        "                    showlegend=False\n",
        "                )\n",
        "\n",
        "                st.plotly_chart(fig_comparison, use_container_width=True)\n",
        "\n",
        "                # Direct comparison\n",
        "                comparison_df = pd.DataFrame({\n",
        "                    'Profile_ID': range(len(profiles_df)),\n",
        "                    'Profile_Name': profiles_df['name'].values,\n",
        "                    'GNN_Score': gnn_avg_scores,\n",
        "                    'GAT_Score': gat_avg_scores,\n",
        "                    'Difference': gat_avg_scores - gnn_avg_scores\n",
        "                })\n",
        "\n",
        "                st.subheader(\"Detailed Comparison\")\n",
        "                st.dataframe(comparison_df.head(20))\n",
        "\n",
        "                # Performance insights\n",
        "                st.subheader(\"Model Insights\")\n",
        "\n",
        "                better_gnn = len(comparison_df[comparison_df['Difference'] < 0])\n",
        "                better_gat = len(comparison_df[comparison_df['Difference'] > 0])\n",
        "\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    st.info(f\"**GNN performs better:** {better_gnn} profiles ({better_gnn/len(comparison_df)*100:.1f}%)\")\n",
        "                with col2:\n",
        "                    st.info(f\"**GAT performs better:** {better_gat} profiles ({better_gat/len(comparison_df)*100:.1f}%)\")\n",
        "\n",
        "    elif page == \"Data Explorer\":\n",
        "        st.title(\"üîç Data Explorer\")\n",
        "\n",
        "        # Dataset selector\n",
        "        dataset_choice = st.selectbox(\"Choose Dataset\", [\"Profiles\", \"Jobs\"])\n",
        "\n",
        "        if dataset_choice == \"Profiles\":\n",
        "            st.subheader(\"LinkedIn Profiles Dataset\")\n",
        "\n",
        "            # Basic statistics\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                st.metric(\"Total Profiles\", len(profiles_df))\n",
        "            with col2:\n",
        "                complete_profiles = len(profiles_df.dropna(subset=['name', 'position', 'about']))\n",
        "                st.metric(\"Complete Profiles\", complete_profiles)\n",
        "            with col3:\n",
        "                with_skills = len(profiles_df[profiles_df['extracted_skills'].apply(len) > 0])\n",
        "                st.metric(\"Profiles with Skills\", with_skills)\n",
        "\n",
        "            # Display sample data\n",
        "            st.subheader(\"Sample Data\")\n",
        "            display_columns = ['name', 'position', 'current_company:name', 'city', 'extracted_skills']\n",
        "            available_columns = [col for col in display_columns if col in profiles_df.columns]\n",
        "            st.dataframe(profiles_df[available_columns].head(10))\n",
        "\n",
        "            # Skills analysis\n",
        "            st.subheader(\"Skills Analysis\")\n",
        "            all_profile_skills = []\n",
        "            for skills in profiles_df['extracted_skills']:\n",
        "                all_profile_skills.extend(skills)\n",
        "\n",
        "            if all_profile_skills:\n",
        "                skill_counts = pd.Series(all_profile_skills).value_counts().head(15)\n",
        "                fig_skills = px.bar(\n",
        "                    x=skill_counts.values,\n",
        "                    y=skill_counts.index,\n",
        "                    orientation='h',\n",
        "                    title=\"Most Common Skills in Profiles\"\n",
        "                )\n",
        "                fig_skills.update_layout(yaxis={'categoryorder':'total ascending'})\n",
        "                st.plotly_chart(fig_skills, use_container_width=True)\n",
        "\n",
        "        else:  # Jobs dataset\n",
        "            st.subheader(\"LinkedIn Job Postings Dataset\")\n",
        "\n",
        "            # Basic statistics\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                st.metric(\"Total Jobs\", len(jobs_df))\n",
        "            with col2:\n",
        "                with_salary = len(jobs_df.dropna(subset=['max_salary']))\n",
        "                st.metric(\"Jobs with Salary Info\", with_salary)\n",
        "            with col3:\n",
        "                remote_jobs = len(jobs_df[jobs_df['remote_allowed'] == 1])\n",
        "                st.metric(\"Remote Jobs\", remote_jobs)\n",
        "\n",
        "            # Display sample data\n",
        "            st.subheader(\"Sample Data\")\n",
        "            display_columns = ['title', 'company_name', 'location', 'formatted_work_type', 'extracted_skills']\n",
        "            available_columns = [col for col in display_columns if col in jobs_df.columns]\n",
        "            st.dataframe(jobs_df[available_columns].head(10))\n",
        "\n",
        "            # Salary analysis\n",
        "            if 'max_salary' in jobs_df.columns and jobs_df['max_salary'].notna().sum() > 0:\n",
        "                st.subheader(\"Salary Distribution\")\n",
        "                salary_data = jobs_df.dropna(subset=['max_salary'])\n",
        "                fig_salary = px.histogram(\n",
        "                    salary_data,\n",
        "                    x='max_salary',\n",
        "                    title=\"Maximum Salary Distribution\",\n",
        "                    nbins=30\n",
        "                )\n",
        "                st.plotly_chart(fig_salary, use_container_width=True)\n",
        "\n",
        "else:\n",
        "    st.error(\"Please ensure the dataset files are available in the correct location.\")\n",
        "    st.info(\"Expected files: 'linkedinuserprofiles.csv' and 'postings.csv'\")\n",
        "\n",
        "# === TAMBAHKAN ANIMATED LOADING SPINNER ===\n",
        "def show_loading_animation():\n",
        "    \"\"\"Menampilkan animasi loading yang menarik\"\"\"\n",
        "    st.markdown(\"\"\"\n",
        "    <div style=\"display: flex; justify-content: center; align-items: center; height: 100px;\">\n",
        "        <div style=\"animation: spin 1s linear infinite; font-size: 3rem;\">üîÑ</div>\n",
        "        <div style=\"margin-left: 1rem; color: #3498db; font-weight: 600;\">\n",
        "            Processing with AI Magic...\n",
        "        </div>\n",
        "    </div>\n",
        "    <style>\n",
        "        @keyframes spin {\n",
        "            0% { transform: rotate(0deg); }\n",
        "            100% { transform: rotate(360deg); }\n",
        "        }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# === ENHANCED FOOTER ===\n",
        "# Ganti bagian footer dengan ini:\n",
        "st.markdown(\"\"\"\n",
        "<div class=\"footer\">\n",
        "    <div style=\"display: flex; justify-content: center; align-items: center; flex-wrap: wrap; gap: 2rem;\">\n",
        "        <div style=\"display: flex; align-items: center;\">\n",
        "            <span style=\"font-size: 1.5rem; margin-right: 0.5rem;\">üöÄ</span>\n",
        "            <span style=\"color: #2c3e50; font-weight: 500;\">Job Matching System v2.0</span>\n",
        "        </div>\n",
        "        <div style=\"display: flex; align-items: center;\">\n",
        "            <span style=\"font-size: 1.5rem; margin-right: 0.5rem;\">üß†</span>\n",
        "            <span style=\"color: #2c3e50; font-weight: 500;\">Powered by Neural Networks</span>\n",
        "        </div>\n",
        "        <div style=\"display: flex; align-items: center;\">\n",
        "            <span style=\"font-size: 1.5rem; margin-right: 0.5rem;\">‚ö°</span>\n",
        "            <span style=\"color: #2c3e50; font-weight: 500;\">Real-time Processing</span>\n",
        "        </div>\n",
        "    </div>\n",
        "    <div style=\"margin-top: 1rem; padding-top: 1rem; border-top: 1px solid rgba(255,255,255,0.1);\">\n",
        "        <span style=\"color: #bdc3c7; font-size: 0.9rem;\">\n",
        "            ¬© 2024 Advanced Job Matching System | Built with ‚ù§Ô∏è and AI\n",
        "        </span>\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOBS2xio3QVD",
        "outputId": "dd1b1ed6-e63d-4e7c-9e35-8134287be9e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Password"
      ],
      "metadata": {
        "id": "squFMdYqLOiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAo_e2N_2mct",
        "outputId": "abb26f85-50e6-480c-9663-6557a3fc86fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 35.196.243.167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Localtunnel akan meminta IP/Password untuk mengamankan koneksi.\n",
        "\n",
        "Salin IP yang dihasilkan dari output kode di atas (misal: 104.199.118.169).\n",
        "\n",
        "Tempelkan IP tersebut di situs yang akan anda buka di bawah ini."
      ],
      "metadata": {
        "id": "BtpFc0K4LEFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menjalankan Streamlit di background:"
      ],
      "metadata": {
        "id": "dppvKKxtJwoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "eVbvY_dr2Drh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langkah 3: Akses Dashboard"
      ],
      "metadata": {
        "id": "Wxob6WOBIvCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1wRlqXa2F9K",
        "outputId": "c1f24250-f2fc-4a6d-8dee-9434d5e06f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0Kyour url is: https://eleven-experts-throw.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Akses situs dengan link yang otomatis ter generate di atas\n",
        "\n",
        "Lalu, masukkan password yang telah didapatkan sebelumnya di dalam situs"
      ],
      "metadata": {
        "id": "gJheF77ZLaom"
      }
    }
  ]
}